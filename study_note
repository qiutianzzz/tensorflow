https://mail.usst.edu.cn/

https://blog.csdn.net/c20081052/article/details/80391627

https://blog.csdn.net/xys430381_1/article/details/93708779


ï½ž/tensorflow/data/

http://data1.f3322.net:666/share/Pascal%20VOC/2012/

https://pjreddie.com/projects/pascal-voc-dataset-mirror/




from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory

2019-09-04 03:39:29.675296: I tensorflow/core/common_runtime/bfc_allocator.cc:818] total_region_allocated_bytes_: 7121543936 memory_limit_: 7435491738 available bytes: 313947802 curr_region_allocation_bytes_: 8589934592
2019-09-04 03:39:29.675307: I tensorflow/core/common_runtime/bfc_allocator.cc:824] Stats: 
Limit:                  7435491738
InUse:                  3240957184
MaxInUse:               7121160704
NumAllocs:                10620469
MaxAllocSize:           1736667648

2019-09-04 03:39:29.675330: W tensorflow/core/common_runtime/bfc_allocator.cc:319] _____*____**______************_________************____***********___*************__________***_****
2019-09-04 03:39:29.675355: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at conv_grad_input_ops.cc:903 : Resource exhausted: OOM when allocating tensor with shape[32,64,300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
I0904 03:39:29.718337 140413882488640 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.ResourceExhaustedError'>, 2 root error(s) found.
  (0) Resource exhausted: OOM when allocating tensor with shape[32,64,300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node gradients/ssd_300_vgg/conv1/conv1_2/Conv2D_grad/Conv2DBackpropInput (defined at /home/leon/tensorflow/SSD-Tensorflow/deployment/model_deploy.py:265) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[train_op/_765]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: OOM when allocating tensor with shape[32,64,300,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node gradients/ssd_300_vgg/conv1/conv1_2/Conv2D_grad/Conv2DBackpropInput (defined at /home/leon/tensorflow/SSD-Tensorflow/deployment/model_deploy.py:265) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node gradients/ssd_300_vgg/conv1/conv1_2/Conv2D_grad/Conv2DBackpropInput:
 ssd_300_vgg/conv1/conv1_2/weights/read (defined at /home/leon/tensorflow/SSD-Tensorflow/nets/ssd_vgg_300.py:452)

Input Source operations connected to node gradients/ssd_300_vgg/conv1/conv1_2/Conv2D_grad/Conv2DBackpropInput:
 ssd_300_vgg/conv1/conv1_2/weights/read (defined at /home/leon/tensorflow/SSD-Tensorflow/nets/ssd_vgg_300.py:452)

Original stack trace for 'gradients/ssd_300_vgg/conv1/conv1_2/Conv2D_grad/Conv2DBackpropInput':
  File "train_ssd_network.py", line 394, in <module>
    tf.app.run()
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/leon/.local/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/leon/.local/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "train_ssd_network.py", line 348, in main
    var_list=variables_to_train)
  File "/home/leon/tensorflow/SSD-Tensorflow/deployment/model_deploy.py", line 301, in optimize_clones
    optimizer, clone, num_clones, regularization_losses, **kwargs)
  File "/home/leon/tensorflow/SSD-Tensorflow/deployment/model_deploy.py", line 265, in _optimize_clone
    clone_grad = optimizer.compute_gradients(sum_loss, **kwargs)
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py", line 512, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 158, in gradients
    unconnected_gradients)
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py", line 731, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py", line 403, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py", line 731, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py", line 596, in _Conv2DGrad
    data_format=data_format),
  File "/home/leon/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 1407, in conv2d_backprop_input
    name=name)
